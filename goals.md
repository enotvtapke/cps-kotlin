## Global goals
* Пофиксить/обойти, что изменение внутреннего состояния парсера между леворекурсивными вызовами приводит к бесконечной рекурсии
	* Кажется, обойти это невозможно. Как вариант можно заставить пользователя хранить в состоянии только те величины, которые имеют конечное число значений при леворекурсивных вызовах. Например, тогда нельзя будет хранить в State глубину дерева разбора. Надо заметить, что здесь проблема даже не в монадичности.
* Пофиксить/обойти, что одинаковые парсеры с одинаковыми типовыми параметрами вызываются много раз
	* Кажется, что разные таблицы мемоизации в одинаково параметризованном парсере могут привести лишь к значительному уменьшению производительности, но не к некорректной работе парсера. Главное, чтобы все нетерминалы, вызывающиеся леворекурсивно (непосредственно или не непосредственно), были мемоизированы. Так будет обеспечена корректность работы парсера. При соблюдении этого требования, но в отсутствии дополнительной мемоизации парсер должен работать корректно, однако со скоростью обычного монадического комбинатора парсеров.
* Описать формальную семантику и синтаксис CPS комбинаторов
* Понять, почему парсер на Lama работает медленно
	* Скорее всего дело в выделении памяти или в работе стандартных коллекций (Выявлено, что время работы сильно зависит от возвращаемых значений парсера, то есть от того, что находится в rs. Если в rs просто строки,то парсер работает быстро, если там S expressions, то значительно медленнее, если там замыкания - примерно в 2 раза медленнее, чем с S expressions)
* Доказать, что в ks не может оказаться одинаковых продолжений или что одинаковые продолжения в ks ни на что не влияют 
	* Нельзя хранить продолжения в set, потому что есть валидные ситуации, при которых в ks должны лежать структурано одинаковые продолжения, которые соответсвтуют разным вариантам разбора. Например, рассмотрим следующую грамматику на вводе "ab":
		```
		S -> A "b"
		  -> A "b"

		A -> "a"
		```
	Должно получиться два результата с одинаковыми деревьями разбора. Если же в ks хранить только разные продолженя, то результат будет один, потому что два продолжения "b" и "b" будут учтены лишь единожды. Разумеется этот пример предполагает, что парсер разбирает неоднозначную грамматику.
	* Пример, при котором ks не может быть set также показывает, что нам нужно запретить, чтобы в ks лежали только одинаковые "по ссылке" продолжения (то есть продолжения из одной и той же ветки одного и того же правила), а не просто струкрутрно одинаковые продолжения (то есть равные как бы по equals). Рассмотрим ситуацию, когда в продолжении некоторого парсера могут лежать одинаковые (в смысле "по ссылке") продолжения. Заметим, что для добавления продолжения парсера в одно и то же множество ks этот парсер должен быть вызван из одного и того же state. 

	Пусть существует "проблемный" мемоизированный парсер A, в списке продолжений которого лежат два одинаковых продолжения. Если это так, значит данный парсер был вызван два раза из одной и той же альтернативы какого-то другого парсера, назовём этот родительский парсер P. Чтобы A был вызван с одним и тем же продолжением дважды, необходимо, чтобы P был вызван дважды с одним тем же state. К вызову P может привести вызов какого-то другого парсера (1), либо вызов P (2). Рассмотрим 2. Если к вызовы P привёл P, значит, P рекурсивный. При этом принимая во внимания факт, что между вызовами state не должен 

## 13.01.2024

## 06.02.2024
Подходы для устранения незавершения dpc:

1. Отслеживать максимумальное число поглощённых символов среди альтернатив нетерминала. Если число не увеличивается, то надо возвращать пустой список в качестве результата разбора нетермирала.  
**Не работает** 
```
	C -> [C]c
	  -> a
```
На такой грамматике строчка acс не будет принята, потому что максимальное число поглощённых символов в альтернативе всегда будет 1 (будет поглощаться символ a).

1. Отслеживать ситуацию, когда в результате раскрытия def1 возвращается def2. Если в def2 первый парсер seq совпадает с первым парсеров seq в def1, поток ввода не изменился и при этом других результатов у def1 нет, то надо возвращать пустой список в результате раскрытия def1.  
**Не работает для опосредованной левой рекурсии**
```
	A -> [B]
	B -> [C]
	C -> [A]
```
На такой грамматике при любом вводе первый парсер в def1 не будет совпадать с первым парсером в def2.

1. Отслеживать раскрытие def. Пока при раскрытии def есть хотя бы один результат, в котором поглотился символ, нужно продолжать раскрывать. Если же в результате раскрытия def вернулись только такие результаты, в которых не изменился поток ввода, то в качестве результата def нужно вернуть пустой список.  
**Не работает** 
```
	A -> [B]
	B -> b
```
Не примет строчку b, потому что при раскрытии A вернётся def без поглощения символов.

1. Отслеживать максимальное число поглощённых символов при раскрытии def. При раскрытии def мы получаем множество результатов с недоразобранными остатками ввода. Найдём крайтчайший недоразобранный остаток ввода. Длина этого остатка характеризует максимальное число поглощённых символов при разборе def. Передадим эту длину при вызове всех def1 получившихся в результате разбора def. Все def1 также посчитают максимальное число поглощённых символов. Если для некоторого def1 число это будет меньше, чем у родительского def, то возвращаем пустой список в качестве результата этого def1.  
**Не работает**  
Например для для опосредованной левой рекурсии  
```
	A -> [B]
	B -> [C]
	C -> [A]
```

## 08.02.2024
В сущности подход dpc есть наивный рекурсивный спуск (без мемоизации, без предсказания следующего нетерминала (как в LL1, LL2, ...)), но с возможностью удобно анализировать состояние разбора. *Задача сейчас сводится к тому, чтобы в этом состоянии определить зацикливание в левой рекурсии и разрешить его.*  
(Пока будем считать, что состояние разбора есть последовательность символов, которая может лишь уменьшаться)  

Чтобы решить задачу нужно уметь определять две вещи:

1. Что при разборе нетерминала происходит леворекурсивный вызов
	* В нашем случае определим леворекурсивный вызов так:  
	Если при разборе (1) некоторого нетерминала A возникла необходимость разобрать этот же нетерминал A и при этом после начала разбора (1) не было поглощено символов потока ввода (не изменилось состояние разбора), назовём эту необходимость левой рекурсией. Или `A =>+ A$\alpha$`
	**Гипотетические методы определения левой рекурсии:**
		1. Для каждого def будем хранить множество нетерминалов, которые являются его родительсвким нетерминалами разного уровня. Такие нетерминалы представляют собой функции, будем хранить ссылки на эти функции. К каждой функции припишем состояние разбора, на котором эта функция была вызвана (само это состояние не должно учитываться при поиске по множеству). Теперь делая вызов любого def, будем проверять, есть ли первый парсер из его seq в множестве родителей для этого def. Если родитель найден (если родителей несколько, то берём того, что добавлен в множество последним), то проверяем состояние разбора текущего def с тем, на котором был вызван родитель. Если состояние совпало, то это левая рекурсия. (Если родителей было несколько, то при несовпадении состояний, необъодимо проверить всех родителей.)
		1. Предположим, что мы раскрываем некоторый def из общего списка результатов. У нас получается список результатов, пройдёмся по отсроченным результатам (назовём каждый из них def1) из него и отфильтруем def1 такие, что первый парсер def1 и первый парсер def равны (это будет сравнение функций по ссылке (будем считать, что мы храним seq как список парсеров (то есть функций))). Среди убранных из списка def1 переложим те def1, состояние которых не равно состоянию, на котором был вызван def, в список неотложенных результатов. Оставшиеся убранные def1 яляются отложенными леворекурсивными парсерами. С оставшимися отсроченными парсерами из результатов def повторим действия по раскрытию аналогичные тем, что мы провели с def. Рано или поздно список отложенных результатов после фильтрации должен опустеть. Останется список неотложенных результатов(этот список в том числе будет содержать отложенные леворекурсивные парсеры с изменившемся состоянием) и список леворекурсивных отложенных результатов. Если список не отложенных результатов пуст, то фейлим def. Если список результатов не пуст, положим оба полученных списка в общий список результатов (чтобы тот был разобран далее).  
		*В целом идея данного подхода заключается в том, что мы вычисляем все ветки разбора либо до состояния левой рекурсии, либо до состояния, когда был поглощён символ входного потока. Если говорить в терминах Д.Ю., то мы ищем, в какой момент считать максимум поглощённых символов.*
			* Это не работает в случае, когда `С =>+ C`, то есть когда нетерминал превращается в сам себя. Чтобы это преодолеть, можно в итоговом списке отложенных леворекурсивных результатов проверить, что сущетсвуют результаты с длиной seq больше 1.  
			* Изменим структуру Deferred. Пусть Deferred вместе с отсроченным парсером также хранит парсер, который привёл к отсрочке. Именно этот парсер надо сравнивать при фильтрации списка.
			* Данный алгоритм можно несколько изменить. Для этого вместо перекладывания def1, у которых поменялось состояние, в список неотложенных результатов будем перекладывать эти def1 обратно в список отложенных результатов, который мы фильтровали. Тогда мы раскроем их на следующей итерации алгоритма. А в итоговом результате алгоритма в списке неотложенных результатов действительно будут только неотложенные результаты. Итоговый алгоритм получится следующим.  
			**Алгоритм раскрытия deferred результата:**

				1. Назовём раскрываемый результат def. Запустим отсроченный парсер внутри def. В результате получится список результатов, назовём его defRes.
				1. Разделим элементы defRes на два списка. В первый список, называемый defRes1, положим элементы defRes, которые:
					1. Являются отсроченными
					1. Имеют своим первым парсером парсер, равный def (в предполагаемый реализации это значит, что в списке seq рассматриваемого элемента defRes первый элемент должен быть равен def)
					1. Имеют state, равный состоянию результата def  

					Во второй список, называемый defRes2, положим все остальные элементы списка defRes.
				1. Для каждого отсроченного парсера из defRes2
					1. Применить алгоритм раскрытия deferred результата
				1. Результаты применения алгоритма для каждого отсроченного элемента defRes2 сконкатенировать в список, названный defResImm
				1. Добавить в defResImm неотложенные парсеры из defRes2
				1. Если defRes1 не пуст и defResImm пуст, вернуть пустой список
				1. Иначе вернуть defRes1 + defRes2

```
A -> Ca
  -> a
C -> Ac
  -> Cd
```
"eee"

```
def // раскрываемые результат

defRes = def.parser(def.state)
defRes1, defRes2 = [], []
for res in defRes:
	if res is Deferred && res.parser.first() == def.parser && res.state == def.state:
		defRes1 += res
	else:
		defRes2 += res

```

1. Что этот леворекурсивный вызов обречён на провал


Как избавляться от опосредованной левой рекурсии путём перестраивания грамматики: https://neerc.ifmo.ru/wiki/index.php?title=Устранение_левой_рекурсии

Опишем, что должен вернуть вызванный deferred парсер с помощью инвариантов:  
Пусть есть стэк разбора, который хранит информацию о том, в рамках каких нетерминалов идёт разбор и с какими состояниями. 

1. Парсер должен вернуть список результатов, таких что:
	1. Результат неотложенный
	1. Или первый парсер отложенного результата присутствует в стэке разбора с состоянием равному тому, что в стэке.

```

T -> T + T
  -> T - T
  -> t
```
t+t

1. Кажется, что подход Дмитрия Юрьевича неверный, потому что парсер при развёртывании в левую рекурсию может некоторое время не поглощать элементы, а потом начать это делать. 
	1. Пример:
		```
		A -> Ca
		  -> a
		C -> Ac
		  -> Cd
		```
		C - стартовый нетерминал
		"acacddd"

	1. Вот упрощённый пример
		```
		C -> Сc
		  -> Cd
		  -> e
		```
		"ecccddd"

		Здесь нужная ветка анализа будет несколько итераций левой рекурсии поглощать лишь 1 символ "e", а потом фейлится, но потом (когда на конце накопится 3 "d") парсер начнёт поглощать всё больше элементов и в итоге примет всю строку ввода.

	1. При этом есть случае, когда количество поглощённых символов не увеличивается и увеличиваться не будет. Например:
		```
			C -> [C]c
			  -> a
		```
		"aaa"

		Здесь всегда будет поглощаться один символ, но, сколько бы итераций левой рекурсии не произошло, больше символов не поглотится.

		```
			C -> aC'
			C'-> cC'
			C'-> eps 
		```

## 23.02.2024
**По итога встречи:**  
Изучить две статьи с новым подходом. Одна ostap, другая статья Фроста. Ждать ответ на отосланный ДЮ контрпример. Сделать всё как можно быстрее, по итогам связаться. Реализация нового подхода есть в Lama.

Подход из статьи Parser Combinators for Ambiguous Left-Recursive Grammars связан с отрубанием леворекурсивных веток длины, которая превышает длину остатка ввода.

Библиотека в haskell с парсерами в CPS стиле https://hackage.haskell.org/package/Agda-2.6.3/docs/Agda-Utils-Parser-MemoisedCPS.html.


## 29.02.2024
**По итога встречи:**
Изучить:

1. Алгоритм Кока янгера косами
1. Алгоритм Эрли

*Проверить:*
Если грамматика LL(k), то будет работать метод Булычев

*Попробовать:*
В случае сбоя переходить на более тяжёлый способ разбора (CPS)

*Мотивация:*
Большая часть грамматик LL(k)

Почитать про Selectable парсер комбинаторы.

Комплексный подход, объединяющий комбинатор inner и deferred. Можно использовать комбинатор, когда мы в deferred нашли левую рекурсию.

## 05.02.2024
Вы посмотрели доказательство.
Показать график. Спросить про 

Если доказательство при котором верно, что dpc работает для ll(k) верно, то хотелось бы сделать монадический парсер на основе dpc. Но не очень ясно как. Потому что во первых мы используем статическую структуру Seq, чтобы сравнивать парсеры внутри для определения левой рекурсии, а во вторых 

Чем плох алгоритм Эрли, он ведь не боится левой рекурсии.


Запустить Ostap на Ocaml.
Запустить deferred парсер на вводе, который быстро работает на Lama.
Внимательно прочитать док-ва из Meercat.



Весь парсер описывается путь dsl. deferred хранить 
parser будет апликативным.

Проблемы:
1. Если использовать DSL, то структуры получаются рекурсивные. Такие структуры нельзя сравнивать
1. Если использовать апликатив DSL, то структуры должны хранить функции, которые нельзя сравнивать
1. Строго говоря, нам не нужно сравнивать парсеры в общем виде. Нам нужно лишь понимать, что мы вызвали парсер, который в данный момент парсится, то есть попали в левую рекурсию. Я полагаю, что при такой реализации достаточно сравнивать функции по ссылке. Возможно, как-то можно распространить идею с fix из изначальной реализации на опосредованную рекурсию.
1. 

```
E -> Ee
E -> f

F -> (E)
```

## 13.02.2024
Выглядит так, что текущая реализация deferred парсера без мемоизации работает за время сопостовимое с временем работы простого монадического парсера. Однако из-за использования левой рекурсии в описании грамматик даже на простейших примерах deferred парсер может работать очень долго. Гипотиза в том, что в обычных монадических парсерах, в которых нельзя задавать леворекурсивыне грамматики, тупиковые ветви разбора отсекаются естественным образом, при этом происходит это очень быстро. 
1. Написать грамматику для арифметических выражений нелеворекурсивно и сравнить время работы с обычным монадическим парсер комбинатором.
1. Протестировать парсер на грамматике с опосредованной левой рекурсией.
1. Текущая реализация deferred работает ооочень медленно без мемоизации. Медленнее, чем обычный deferred парсер. Это было проверено с помощью ввода "(((((((((((42)))))))))))". Предположительно такое поведение наблюдается, так как для обрубания тупиковых леворекурсивных ветвей в текущей реализации deferred по сути используется bfs. А вот в наивной реализации deferred честный dfs. Попытка завершать текущую реализацию deferred преждевременно при нахождении результата, когда весь ввода разобран, не помогла. 
1. Без мемоизации парсер использовать нереально. Время работы, судя по всему, n^n на вводе типа "(((((((((((42)))))))))))". Каждый Expr в стэке вызовов, который в данном случае имеет глубину O(n)

1. Чтобы не делать хэш консинг можно выдать в начале исполнения (например, с помозью stable name) всем парсерам (в том числе парсерам высшего порядка) метки. В парсерах высшего порядка при передачи парсеров-аргументов необхоимо совмещать метку парсера высшего порядка с метками парсера-аргумента консистентным образом. Тогда даже параметризованные парсеры будут обладать меткой, по которой их можно сравнивать.

В каждом цикле левой рекурсии есть ответственный за этот цикл узел, это главный узел. Это тот узел, который был вызван первым. В цикле есть транхитные узлы и концевой узел. Концевой узел это тот узел, который совершил вызов к главному. При вызове к главному узлу мы возвращаем отложенный результат. Для этого мы проверяем наличия узла в стэке. Теперь концевой узел, а также все транзитные узлы должны пробросить отложенный результат обратно к главному узлу. Для этого узлы сравнивают глубину возникновения отложенного результата с собственной глубиной. Если глубина возникновения отложенного результата меньше собственной, то надо пробросить отложенный результат. Когда отложенный результат возвращается в главный узел, тот проверяет, что у него есть непосредственные результаты и в случае их наличия запускает отложенный результат (по сути обращаясь к себе), при этом заменяя стэк в отложенном результате на свой собственный. Таким образом мы заходим на следующую итерацию цикла.

Когда главный узел принял решение, необходимо убрать его из стэка.

Во всех узлах отлоденный результат может быть максимум один, так как наша грамматика LLk и однозначная. Это соответствует тому, что каждый узел в графе леворекурсивных выводов лежит на не более чем одном цикле.

Надо заметить, что транзитные узлы узнают, что они транзитные только окгда получают отложенный результат, который указывает на узел на стжке выше, чем сами эти узлы. Таким обзом парсер работает в ситуации, когда для получения непосредственного результата необходимо покрутиться в рекурсии дочернего узла.


[(Ededa, "State(s=, invocationStack=InvocationStack(impl=[InvocationStackElement(parser=monadicParser.ParserM$alt$1@45283ce2, state=Ededa), InvocationStackElement(parser=monadicParser.ParserM$alt$1@2077d4de, state=Ededa)]), depth=-1)")]

Мне нужны грамматики.

1 проверить классический алгоритм dps на выражениях из Lama, предварительно добавив туда семантика
2 доминаторы, потоковые графы, natural loop, компонент сильной связности. Чтобы была терминология
3 проверить время работы ostap на ocaml
4 

Здравствуйте, я запускал оригинальный deferred парсер, чтобы понять, может ли он работать за экспоненту на LL(k) грамматиках. Судя по моим наблюдениям, оказалось, что такое возможно.

Рассмотрим следующую грамматику (каждый вызов к нетерминалу отсроченный): 
```
E -> E 'e'
	 F
F -> '(' E ')'
	 'f'
```

На вводе `((((fe))))` и ему подобных (`((feeee))`, `((((((((((((f))))))))))))`) время работы экспоненциально зависит от числа '('. Так случается, потому что пока первый символ ввода равен '(' каждый вызов к E приводит к двум вызовам E: один вызов происходит по правилу `E -> E 'e'`, другой - опосредованно через правила `E -> F` и `F -> '(' E ')'`. 

Прикладываю картинку для первых 4 шагов вызова нетерминала F на вводе `((((fe))))`. На картинке отображено, во что раскрываются deferred результаты разбора, они заключены `⟨...⟩`. Зафейленные результаты заключены в `-...-`, на них можно не обращать внимания. 

((((((((((((fee)))))))))))))

## 20.03.24
1. Можно решить проблему с экспоненциальной сложностью на грамматиках вида
```
E -> E 'e'
	 F
F -> '(' E ')'
	 'f'
```
путём мемоизации. 
1. Тем не менее любая попытка расширить текущий алгоритм на LL(k), по всей видимости, приведёт к экспоненциальной сложности.
На грамматиках вида 
```
C -> Сc
  -> Cd
  -> e
```
чтобы понять, какой вариант выбрать, нужно раскрыть правило C O(n) раз, так как грамматика не LL(k). При этом при каждом раскрытии перебираются продолжения C, состоящие из 'c' и 'd', всего таких продолжений 2^n. То есть нам потенциально нужно перебрать 2^n вариантов, чтобы принять решение. 
Если говорить неформально, то мы не знаем, что там в конце ввода, поэтому нельзя отрезать какие-либо deferred парсеры.

Совершенно неясно, как сделать алгоритм, который работает быстрее, чем за линию без lookahead.

1. Есть ли языки, в которых можно будет использовать парсеры высшего порядка. То есть такие языки, где предусматривается несколько вариантов синтаксиса.
1. Для чего вообще это можно использовать. Для языков программирования подход слишком медленный. Для всяких dsl на коленке? Но для них не надо развёртывать такой инструментарий, легче использовать обычный монадический комбинаторный парсер или cps парсер без hash-consing.

```
b = a bind \t -> if t then term "a" else term "b"
c = a bind \t -> if t then term "a" else term "b"
```

layout based parser
сиестерские парсер комбинаторы
generalized monads to arrows (huston)
Нет мемоизации по семантике
Попробовать cps на полиндроме
p(x) = lambda stream -> p(x) bind 

detenal name haskell

существенная ли мемоизация по семантике
Если да, то найти момент, который начнёт тормозить
